import subprocess
import os
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from matplotlib.patches import Rectangle
from mpl_toolkits.mplot3d import Axes3D
from scipy.stats import pearsonr, spearmanr
from scipy.interpolate import griddata
import warnings
warnings.filterwarnings('ignore')

# Try importing scikit-optimize libraries
try:
    from skopt import gp_minimize
    from skopt.space import Categorical
    from skopt.utils import use_named_args
    from skopt.plots import plot_convergence, plot_objective, plot_evaluations
except ImportError:
    print("Warning: scikit-optimize not found. Bayesian optimization will be disabled.")
    print("Install with: pip install scikit-optimize")

# =================================================================
# 1. CONFIGURATION SECTION
# =================================================================

# Path configuration
KMC_EXECUTABLE_PATH = "/Users/yueyue/CLionProjects/untitled3/cmake-build-debug/integrated_kmc"

# =================================================================
# 2. ANALYSIS MODES CONFIGURATION
# =================================================================

# Mode 1: Single detailed analysis
DO_SINGLE_ANALYSIS = False
ANALYSIS_TEMP = 343.0
ANALYSIS_RATIO = 0.003
ANALYSIS_OUTPUT_DIR = os.path.join("output", f"analysis_results_T{ANALYSIS_TEMP}_R{ANALYSIS_RATIO}")

# Mode 2: Parameter sweep for defect investigation
DO_PARAMETER_SWEEP = False
SWEEP_OUTPUT_DIR = os.path.join("output", "parameter_sweep_results")

# Temperature range for parameter sweep (K)
TEMP_RANGE = np.arange(323.0, 373.0 + 0.1, 10.0)  # Every 10K from 323K to 373K
# Initiator ratio range
RATIO_RANGE = np.arange(0.001, 0.005 + 1e-6, 0.001)  # Every 0.001 from 0.001 to 0.005

# Mode 3: Bayesian optimization with chain length constraint
DO_OPTIMIZATION = True

# Optimization parameter space (can be different from sweep)
#temp_values = list(np.arange(323.0, 373.0 + 1e-6, 2.0))
#ratio_values = list(np.arange(0.001, 0.005 + 1e-9, 0.0001))
temp_values = list(np.arange(323.0, 373.0 + 1e-6, 1.0))
ratio_values = list(np.arange(0.001, 0.005 + 1e-9, 0.0002))

if 'gp_minimize' in globals():
    dim_temp = Categorical(categories=temp_values, name='poly_temp')
    dim_ratio = Categorical(categories=ratio_values, name='poly_initiator_ratio')
    dimensions = [dim_temp, dim_ratio]

# Optimization settings
N_CALLS = 120
N_INITIAL_POINTS = 20

# =================================================================
# 3. CHAIN LENGTH CONSTRAINT CONFIGURATION
# =================================================================

# Chain length constraint parameters
MIN_CHAIN_LENGTH = 1000.0  # ÊúÄÂ∞èÂπ≥ÂùáÈìæÈïøË¶ÅÊ±Ç
CHAIN_LENGTH_PENALTY_FACTOR = 1000.0  # ËøùÂèçÁ∫¶ÊùüÊó∂ÁöÑÊÉ©ÁΩöÂõ†Â≠ê
USE_SOFT_CONSTRAINT = True  # True: ËΩØÁ∫¶Êùü(ÊÉ©ÁΩö), False: Á°¨Á∫¶Êùü(ÊãíÁªù)

# Áî®‰∫éËÆ∞ÂΩï‰ºòÂåñÂéÜÂè≤ÁöÑÂÖ®Â±ÄÂèòÈáè
optimization_history = {
    'temperatures': [],
    'ratios': [],
    'total_times': [],
    'chain_lengths': [],
    'constraint_violations': [],
    'objective_values': []
}

# =================================================================
# 4. FUNCTION DEFINITIONS
# =================================================================

def run_single_analysis(temp, ratio, output_dir):
    """Run single detailed analysis with comprehensive output."""
    print("="*60)
    print("üî¨ RUNNING SINGLE DETAILED ANALYSIS")
    print(f"  üìä Temperature: {temp:.1f} K")
    print(f"  üìä Initiator Ratio: {ratio:.4f}")
    print(f"  üìÅ Output Directory: '{output_dir}/'")
    print("="*60)

    os.makedirs(output_dir, exist_ok=True)

    if not os.path.exists(KMC_EXECUTABLE_PATH):
        print(f"‚ùå Error: Executable not found at '{KMC_EXECUTABLE_PATH}'")
        return

    command = [
        KMC_EXECUTABLE_PATH,
        "--analyze",
        str(temp),
        str(ratio),
        output_dir
    ]

    try:
        print("\nüìù C++ Simulation Log:")
        print("-" * 40)
        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)

        for line in iter(process.stdout.readline, ''):
            print(line, end='')
        process.stdout.close()
        return_code = process.wait()

        if return_code == 0:
            print("\n‚úÖ Analysis completed successfully!")
            print(f"üìÅ Check detailed output files in '{output_dir}' folder.")
        else:
            print(f"\n‚ùå Analysis failed with exit code {return_code}")

    except Exception as e:
        print(f"‚ùå Error occurred during analysis: {e}")

    print("\n")

def run_parameter_sweep():
    """Run comprehensive parameter sweep to investigate defect formation."""
    print("="*60)
    print("üîç PARAMETER SWEEP: INVESTIGATING DEFECT FORMATION")
    print(f"  üå°Ô∏è  Temperature range: {TEMP_RANGE[0]:.1f} - {TEMP_RANGE[-1]:.1f} K ({len(TEMP_RANGE)} points)")
    print(f"  ‚öóÔ∏è  Ratio range: {RATIO_RANGE[0]:.4f} - {RATIO_RANGE[-1]:.4f} ({len(RATIO_RANGE)} points)")
    print(f"  üìä Total simulations: {len(TEMP_RANGE) * len(RATIO_RANGE)}")
    print("="*60)

    os.makedirs(SWEEP_OUTPUT_DIR, exist_ok=True)

    if not os.path.exists(KMC_EXECUTABLE_PATH):
        print(f"‚ùå Error: Executable not found at '{KMC_EXECUTABLE_PATH}'")
        return None

    results = []
    total_sims = len(TEMP_RANGE) * len(RATIO_RANGE)
    current_sim = 0

    for temp in TEMP_RANGE:
        for ratio in RATIO_RANGE:
            current_sim += 1
            print(f"\n‚è≥ Running simulation {current_sim}/{total_sims}: T={temp:.1f}K, R={ratio:.4f}")

            command = [
                KMC_EXECUTABLE_PATH,
                "--sweep",
                str(temp),
                str(ratio),
                SWEEP_OUTPUT_DIR,
                str(current_sim)
            ]

            try:
                result = subprocess.run(command, capture_output=True, text=True, check=True, timeout=600)

                # Parse the structured output from C++ program
                # Format: temp ratio unsaturated_frac saturated_frac hh_frac avg_length poly_time depoly_time recyclability
                output_line = result.stdout.strip()
                if output_line:
                    data = output_line.split()
                    if len(data) >= 9:
                        results.append({
                            'temperature': float(data[0]),
                            'initiator_ratio': float(data[1]),
                            'unsaturated_fraction': float(data[2]),
                            'saturated_fraction': float(data[3]),
                            'hh_bond_fraction': float(data[4]),
                            'avg_chain_length': float(data[5]),
                            'polymerization_time': float(data[6]),
                            'depolymerization_time': float(data[7]),
                            'recyclability_index': float(data[8])
                        })
                        print(f"‚úÖ Completed: Recyclability = {float(data[8]):.6f}, Chain Length = {float(data[5]):.1f}")
                    else:
                        print(f"‚ö†Ô∏è  Warning: Unexpected output format")
                else:
                    print(f"‚ö†Ô∏è  Warning: No output received")

            except subprocess.TimeoutExpired:
                print(f"‚è∞ Timeout for T={temp:.1f}K, R={ratio:.4f}")
                results.append({
                    'temperature': temp,
                    'initiator_ratio': ratio,
                    'unsaturated_fraction': np.nan,
                    'saturated_fraction': np.nan,
                    'hh_bond_fraction': np.nan,
                    'avg_chain_length': np.nan,
                    'polymerization_time': np.nan,
                    'depolymerization_time': np.nan,
                    'recyclability_index': np.nan
                })
            except Exception as e:
                print(f"‚ùå Error for T={temp:.1f}K, R={ratio:.4f}: {e}")
                results.append({
                    'temperature': temp,
                    'initiator_ratio': ratio,
                    'unsaturated_fraction': np.nan,
                    'saturated_fraction': np.nan,
                    'hh_bond_fraction': np.nan,
                    'avg_chain_length': np.nan,
                    'polymerization_time': np.nan,
                    'depolymerization_time': np.nan,
                    'recyclability_index': np.nan
                })

    # Convert to DataFrame and save
    df = pd.DataFrame(results)
    csv_file = os.path.join(SWEEP_OUTPUT_DIR, "parameter_sweep_results.csv")
    df.to_csv(csv_file, index=False)

    print(f"\n‚úÖ Parameter sweep completed!")
    print(f"üìä Results saved to: {csv_file}")
    print(f"üìà Valid results: {df.dropna().shape[0]}/{len(df)}")

    return df

def analyze_defect_correlations(df):
    """Analyze correlations between polymerization conditions and defect formation."""
    print("\n" + "="*60)
    print("üìä CORRELATION ANALYSIS: CONDITIONS vs DEFECTS")
    print("="*60)

    if df is None or df.empty:
        print("‚ùå No data available for correlation analysis")
        return

    # Remove rows with NaN values for correlation analysis
    df_clean = df.dropna()

    if df_clean.empty:
        print("‚ùå No valid data for correlation analysis")
        return

    # Define correlation pairs
    condition_vars = ['temperature', 'initiator_ratio']
    defect_vars = ['unsaturated_fraction', 'saturated_fraction', 'hh_bond_fraction', 'avg_chain_length']
    performance_vars = ['polymerization_time', 'depolymerization_time', 'recyclability_index']

    print("\nüîó CORRELATIONS: Polymerization Conditions ‚Üí Defect Formation")
    print("-" * 60)

    for condition in condition_vars:
        for defect in defect_vars:
            if condition in df_clean.columns and defect in df_clean.columns:
                pearson_r, pearson_p = pearsonr(df_clean[condition], df_clean[defect])
                spearman_r, spearman_p = spearmanr(df_clean[condition], df_clean[defect])

                print(f"{condition.replace('_', ' ').title()} ‚Üí {defect.replace('_', ' ').title()}:")
                print(f"  üìà Pearson:  r = {pearson_r:+.3f} (p = {pearson_p:.3f})")
                print(f"  üìä Spearman: œÅ = {spearman_r:+.3f} (p = {spearman_p:.3f})")

    print("\nüîó CORRELATIONS: Defects ‚Üí Recyclability Performance")
    print("-" * 60)

    for defect in defect_vars:
        for performance in performance_vars:
            if defect in df_clean.columns and performance in df_clean.columns:
                pearson_r, pearson_p = pearsonr(df_clean[defect], df_clean[performance])
                spearman_r, spearman_p = spearmanr(df_clean[defect], df_clean[performance])

                print(f"{defect.replace('_', ' ').title()} ‚Üí {performance.replace('_', ' ').title()}:")
                print(f"  üìà Pearson:  r = {pearson_r:+.3f} (p = {pearson_p:.3f})")
                print(f"  üìä Spearman: œÅ = {spearman_r:+.3f} (p = {spearman_p:.3f})")

def create_comprehensive_defect_analysis_plots(df):
    """
    Create a comprehensive 3x4 visualization grid of the parameter sweep results.
    Final version with custom legends for MMD plot.
    """
    if df is None or df.empty:
        print("‚ùå No data available for plotting")
        return

    print("\n" + "="*60)
    print("üìä CREATING RESTRUCTURED 3x4 ANALYSIS PLOT (FINAL LAYOUT)")
    print("="*60)

    # ... (Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÂíåÁΩëÊ†ºÂàõÂª∫ÈÉ®ÂàÜ‰øùÊåÅ‰∏çÂèò) ...
    plt.style.use('default')
    df_clean = df.dropna().copy()
    if df_clean.empty: return
    df_clean['total_time'] = df_clean['polymerization_time'] + df_clean['depolymerization_time']
    df_clean.rename(columns={'recyclability_index': 'process_efficiency'}, inplace=True)
    new_metric_name = 'Process Efficiency Index'
    fig = plt.figure(figsize=(26, 18))
    gs = fig.add_gridspec(3, 4, wspace=0.4, hspace=0.45)

    # --- ÁªòÂà∂Á¨¨‰∏ÄË°å (ÁÉ≠ÂäõÂõæ - ‰øùÊåÅ‰∏çÂèò) ---
    heatmap_vars = {
        'unsaturated_fraction': 'Unsaturated Chains Fraction',
        'saturated_fraction': 'Saturated Chains Fraction',
        'hh_bond_fraction': 'HH-Bond Fraction',
        'avg_chain_length': 'Average Chain Length'
    }
    for i, (var, label) in enumerate(heatmap_vars.items()):
        ax = fig.add_subplot(gs[0, i])
        pivot_data = df_clean.pivot_table(values=var, index='temperature', columns='initiator_ratio')
        sns.heatmap(pivot_data, annot=True, fmt='.3g', cmap='viridis', ax=ax, cbar_kws={'label': label})
        ax.set_xlabel('Initiator Ratio')
        ax.set_ylabel('Temperature (K)')

    # --- ÁªòÂà∂Á¨¨‰∫åË°å ---

    # Âõæ 2-1 & 2-2: ÁÆ±Á∫øÂõæ (‰øùÊåÅ‰∏çÂèò)
    boxplot_palette = ["#e41a1c", "#377eb8", "#4daf4a"]
    for i, col in enumerate(['temperature', 'initiator_ratio']):
        ax_box = fig.add_subplot(gs[1, i])
        range_col = f'{col}_range'
        bins = min(5, len(df_clean[col].unique()))
        df_clean[range_col] = pd.cut(df_clean[col], bins=bins)
        melted_data = df_clean.melt(id_vars=[range_col], value_vars=['unsaturated_fraction', 'saturated_fraction', 'hh_bond_fraction'], var_name='Defect Type', value_name='Defect Fraction')
        sns.boxplot(data=melted_data, x=range_col, y='Defect Fraction', hue='Defect Type', ax=ax_box, palette=boxplot_palette, showfliers=False)
        if col == 'temperature':
            labels = [f"({cat.left:.0f}, {cat.right:.0f}]" for cat in df_clean[range_col].cat.categories]
            ax_box.set_xlabel('Temperature Range (K)')
        else:
            labels = [f"({cat.left:.4f}, {cat.right:.4f}]" for cat in df_clean[range_col].cat.categories]
            ax_box.set_xlabel('Initiator Ratio Range')
        ax_box.set_xticklabels(labels, rotation=45, ha="right")
        ax_box.legend(title='Defect Type')


    # *** --- START OF MODIFICATION --- ***
    # Âõæ 2-3: Log Molar Mass Distribution by Temperature (Êñ∞ÁªòÂõæÈÄªËæë)
    ax_mmd = fig.add_subplot(gs[1, 2])
    df_clean['log_avg_M'] = np.log10(df_clean['avg_chain_length'] * 100.0)

    # 1. ÂÆö‰πâÊ∏©Â∫¶ÂàÜÁªÑ
    num_temp_groups = min(5, len(df_clean['temperature'].unique()))
    df_clean['temp_group_mmd'] = pd.cut(df_clean['temperature'], bins=num_temp_groups)

    # 2. Ëé∑ÂèñÂàÜÁªÑÂíåÈ¢úËâ≤
    temp_groups = df_clean.groupby('temp_group_mmd')
    colors = plt.cm.get_cmap('viridis', temp_groups.ngroups)

    # 3. ÈÅçÂéÜÊØè‰∏™ÂàÜÁªÑÔºåÊâãÂä®ÁªòÂõæÂπ∂ÊåáÂÆölabel
    for i, (name, group) in enumerate(temp_groups):
        if group.empty:
            continue
        # ÂàõÂª∫ÂèØËØªÁöÑÊ†áÁ≠æ
        label = f"{name.left:.0f}-{name.right:.0f}K"
        sns.kdeplot(data=group, x='log_avg_M', ax=ax_mmd, color=colors(i),
                    fill=True, common_norm=False, alpha=0.5, linewidth=1.5, label=label)

    ax_mmd.set_xlabel(r'$\log(M_{avg})$')
    ax_mmd.set_ylabel('Density')
    ax_mmd.legend(title='Temperature Range') # Áé∞Âú®Âõæ‰æãÂ∞ÜÊòæÁ§∫Êàë‰ª¨Ëá™ÂÆö‰πâÁöÑÊ†áÁ≠æ
    # *** --- END OF MODIFICATION --- ***


    # Âõæ 2-4: Correlation Matrix
    ax_corr = fig.add_subplot(gs[1, 3])
    corr_cols = ['temperature', 'initiator_ratio', 'unsaturated_fraction', 'saturated_fraction', 'hh_bond_fraction', 'avg_chain_length', 'process_efficiency']
    corr_matrix = df_clean[corr_cols].corr()
    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
    sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', center=0, ax=ax_corr)
    ax_corr.set_xticklabels(ax_corr.get_xticklabels(), rotation=45, ha="right")
    ax_corr.set_yticklabels(ax_corr.get_yticklabels(), rotation=30, style='italic', ha='right')

    # ... (Á¨¨‰∏âË°åÂíåÁªìÂ∞æÈÉ®ÂàÜÁöÑ‰ª£Á†Å‰øùÊåÅ‰∏çÂèò) ...
    # --- 5. ÁªòÂà∂Á¨¨‰∏âË°å ---
    temp_grid, ratio_grid = np.meshgrid(np.linspace(df_clean['temperature'].min(), df_clean['temperature'].max(), 100),
                                        np.linspace(df_clean['initiator_ratio'].min(), df_clean['initiator_ratio'].max(), 100))
    ax_poly_depoly = fig.add_subplot(gs[2, 0])
    scatter_pd = ax_poly_depoly.scatter(df_clean['polymerization_time'], df_clean['depolymerization_time'], c=df_clean['process_efficiency'], cmap='viridis', s=50, edgecolors='k', linewidth=0.5)
    ax_poly_depoly.set_xlabel('Polymerization Time (s)')
    ax_poly_depoly.set_ylabel('Depolymerization Time (s)')
    fig.colorbar(scatter_pd, ax=ax_poly_depoly, label=new_metric_name)
    ax_eff_time = fig.add_subplot(gs[2, 1])
    scatter_eff = ax_eff_time.scatter(df_clean['total_time'], df_clean['process_efficiency'], c=df_clean['temperature'], cmap='coolwarm', s=50, edgecolors='k', linewidth=0.5)
    ax_eff_time.set_xlabel('Total Cycle Time (s)')
    ax_eff_time.set_ylabel(new_metric_name)
    fig.colorbar(scatter_eff, ax=ax_eff_time, label='Temperature (K)')
    ax_eff_landscape = fig.add_subplot(gs[2, 2])
    efficiency_grid = griddata((df_clean['temperature'], df_clean['initiator_ratio']), df_clean['process_efficiency'], (temp_grid, ratio_grid), method='cubic')
    if not np.all(np.isnan(efficiency_grid)):
        contour_eff = ax_eff_landscape.contourf(temp_grid, ratio_grid, efficiency_grid, levels=20, cmap='RdYlBu')
        fig.colorbar(contour_eff, ax=ax_eff_landscape, label=new_metric_name)
    ax_eff_landscape.set_xlabel('Temperature (K)')
    ax_eff_landscape.set_ylabel('Initiator Ratio')
    opt_idx = df_clean['process_efficiency'].idxmax()
    ax_eff_landscape.plot(df_clean.loc[opt_idx, 'temperature'], df_clean.loc[opt_idx, 'initiator_ratio'], 'r*', markersize=15, markeredgecolor='white', label='Max Efficiency')
    ax_eff_landscape.legend()
    ax_time_landscape = fig.add_subplot(gs[2, 3])
    time_grid = griddata((df_clean['temperature'], df_clean['initiator_ratio']), df_clean['total_time'], (temp_grid, ratio_grid), method='cubic')
    if not np.all(np.isnan(time_grid)):
        contour_time = ax_time_landscape.contourf(temp_grid, ratio_grid, time_grid, levels=20, cmap='viridis_r')
        fig.colorbar(contour_time, ax=ax_time_landscape, label='Total Time (s)')
    ax_time_landscape.set_xlabel('Temperature (K)')
    ax_time_landscape.set_ylabel('Initiator Ratio')
    min_time_idx = df_clean['total_time'].idxmin()
    ax_time_landscape.plot(df_clean.loc[min_time_idx, 'temperature'], df_clean.loc[min_time_idx, 'initiator_ratio'], 'r*', markersize=15, markeredgecolor='white', label='Min Time')
    ax_time_landscape.legend()

    # --- 6. Ê∑ªÂä†ÊÄªÊ†áÈ¢òÂπ∂‰øùÂ≠ò ---
    fig.suptitle('Comprehensive Analysis of Polymerization-Depolymerization Cycle', fontsize=28, fontweight='bold')
    fig.tight_layout(rect=[0, 0, 1, 0.96])

    output_filename = 'structured_analysis_dashboard_final_v3.png'
    plt.savefig(output_filename, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print(f"‚úÖ Final restructured analysis plot saved: '{output_filename}'")

def get_chain_length_from_simulation(poly_temp, poly_initiator_ratio):
    """Ëé∑Âèñ‰ªøÁúüÁªìÊûú‰∏≠ÁöÑÂπ≥ÂùáÈìæÈïø‰ø°ÊÅØ"""
    if not os.path.exists(KMC_EXECUTABLE_PATH):
        print(f"‚ùå Error: Executable not found at '{KMC_EXECUTABLE_PATH}'")
        return None, None

    command = [KMC_EXECUTABLE_PATH, "--sweep", str(poly_temp), str(poly_initiator_ratio), "/tmp", "0"]

    try:
        result = subprocess.run(command, capture_output=True, text=True, check=True, timeout=600)
        output_line = result.stdout.strip()
        if output_line:
            data = output_line.split()
            if len(data) >= 9:
                total_time = float(data[6]) + float(data[7])  # poly_time + depoly_time
                avg_chain_length = float(data[5])
                return total_time, avg_chain_length
    except Exception as e:
        print(f"‚ùå [Chain Length Check] Error occurred: {e}")

    return None, None

@use_named_args(dimensions=dimensions if 'dimensions' in globals() else [])
def objective_with_chain_length_constraint(poly_temp, poly_initiator_ratio):
    """Â∏¶ÈìæÈïøÁ∫¶ÊùüÁöÑÁõÆÊ†áÂáΩÊï∞ - Áé∞Âú®ÂêåÊó∂‰ºòÂåñÊÄªÊó∂Èó¥Âπ∂Á°Æ‰øùÈìæÈïøÊª°Ë∂≥Ë¶ÅÊ±Ç"""
    global optimization_history

    print(f"üéØ [Optimizer] Evaluating: Temp = {poly_temp:.1f} K, Ratio = {poly_initiator_ratio:.4f}")

    if not os.path.exists(KMC_EXECUTABLE_PATH):
        print(f"‚ùå Error: Executable not found at '{KMC_EXECUTABLE_PATH}'")
        return 1e10

    command = [KMC_EXECUTABLE_PATH, "--sweep", str(poly_temp), str(poly_initiator_ratio), "/tmp", "0"]

    try:
        result = subprocess.run(command, capture_output=True, text=True, check=True, timeout=600)
        output_line = result.stdout.strip()

        if output_line:
            data = output_line.split()
            if len(data) >= 9:
                total_time = float(data[6]) + float(data[7])  # poly_time + depoly_time
                avg_chain_length = float(data[5])

                # ËÆ∞ÂΩïÂéÜÂè≤Êï∞ÊçÆ
                optimization_history['temperatures'].append(poly_temp)
                optimization_history['ratios'].append(poly_initiator_ratio)
                optimization_history['total_times'].append(total_time)
                optimization_history['chain_lengths'].append(avg_chain_length)

                # Ê£ÄÊü•ÈìæÈïøÁ∫¶Êùü
                constraint_violation = max(0, MIN_CHAIN_LENGTH - avg_chain_length)
                optimization_history['constraint_violations'].append(constraint_violation)

                if USE_SOFT_CONSTRAINT:
                    # ËΩØÁ∫¶ÊùüÔºöËøùÂèçÁ∫¶ÊùüÊó∂Ê∑ªÂä†ÊÉ©ÁΩö
                    if constraint_violation > 0:
                        penalty = CHAIN_LENGTH_PENALTY_FACTOR * (constraint_violation / MIN_CHAIN_LENGTH) ** 2
                        objective_value = total_time + penalty
                        print(f"‚ö†Ô∏è  [Optimizer] Chain length {avg_chain_length:.1f} < {MIN_CHAIN_LENGTH:.1f}, penalty = {penalty:.2f}")
                        print(f"‚úÖ [Optimizer] Total Time: {total_time:.4f} s, Penalized Objective: {objective_value:.4f}")
                    else:
                        objective_value = total_time
                        print(f"‚úÖ [Optimizer] Total Time: {total_time:.4f} s, Chain Length: {avg_chain_length:.1f} (OK)")
                else:
                    # Á°¨Á∫¶ÊùüÔºöËøùÂèçÁ∫¶ÊùüÊó∂Áõ¥Êé•ËøîÂõûÂ§ßÂÄº
                    if constraint_violation > 0:
                        objective_value = 1e8
                        print(f"‚ùå [Optimizer] Chain length {avg_chain_length:.1f} < {MIN_CHAIN_LENGTH:.1f}, REJECTED")
                    else:
                        objective_value = total_time
                        print(f"‚úÖ [Optimizer] Total Time: {total_time:.4f} s, Chain Length: {avg_chain_length:.1f} (OK)")

                optimization_history['objective_values'].append(objective_value)
                print()
                return objective_value

    except Exception as e:
        print(f"‚ùå [Optimizer] Error occurred: {e}")

    # Â§±Ë¥•ÊÉÖÂÜµ
    optimization_history['temperatures'].append(poly_temp)
    optimization_history['ratios'].append(poly_initiator_ratio)
    optimization_history['total_times'].append(1e10)
    optimization_history['chain_lengths'].append(0)
    optimization_history['constraint_violations'].append(MIN_CHAIN_LENGTH)
    optimization_history['objective_values'].append(1e10)
    return 1e10

def run_bayesian_optimization():
    """ËøêË°åÂ∏¶ÈìæÈïøÁ∫¶ÊùüÁöÑË¥ùÂè∂ÊñØ‰ºòÂåñ"""
    if 'gp_minimize' not in globals():
        print("‚ùå Scikit-optimize not available. Skipping Bayesian optimization.")
        return None

    print("="*80)
    print("üéØ CONSTRAINED BAYESIAN OPTIMIZATION: FINDING OPTIMAL CONDITIONS")
    print(f"Objective: Minimize total cycle time (polymerization + depolymerization)")
    print(f"Constraint: Average chain length ‚â• {MIN_CHAIN_LENGTH:.1f}")
    print(f"Constraint Type: {'Soft (penalty)' if USE_SOFT_CONSTRAINT else 'Hard (rejection)'}")
    if USE_SOFT_CONSTRAINT:
        print(f"Penalty Factor: {CHAIN_LENGTH_PENALTY_FACTOR:.0f}")
    print(f"Parameter Space:")
    print(f"  üå°Ô∏è  Temperature (K): {temp_values}")
    print(f"  ‚öóÔ∏è  Initiator Ratio: {[f'{r:.4f}' for r in ratio_values]}")
    print(f"Running {N_CALLS} evaluations...")
    print("="*80)

    # Ê∏ÖÁ©∫ÂéÜÂè≤ËÆ∞ÂΩï
    global optimization_history
    optimization_history = {
        'temperatures': [],
        'ratios': [],
        'total_times': [],
        'chain_lengths': [],
        'constraint_violations': [],
        'objective_values': []
    }

    # ËøêË°å‰ºòÂåñ
    result_gp = gp_minimize(
        func=objective_with_chain_length_constraint,
        dimensions=dimensions,
        n_calls=N_CALLS,
        n_initial_points=N_INITIAL_POINTS,
        #acq_func='EI',
        acq_func='LCB',      # ‰ΩøÁî® LCB ÈááÈõÜÂáΩÊï∞
        kappa=5.0,
        random_state=123
    )

    # ÊèêÂèñÁªìÊûú
    best_temp = result_gp.x[0]
    best_ratio = result_gp.x[1]
    best_objective = result_gp.fun

    # Ëé∑ÂèñÊúÄ‰ºòÁÇπÁöÑÂÆûÈôÖÊÄßËÉΩÊåáÊ†á
    best_total_time, best_chain_length = get_chain_length_from_simulation(best_temp, best_ratio)

    print(f"\nüèÜ CONSTRAINED OPTIMIZATION RESULTS")
    print(f"  üå°Ô∏è  Best Temperature: {best_temp:.1f} K")
    print(f"  ‚öóÔ∏è  Best Ratio: {best_ratio:.4f}")
    if best_total_time is not None and best_chain_length is not None:
        print(f"  ‚è±Ô∏è  Total Time: {best_total_time:.2f} s")
        print(f"  üîó Chain Length: {best_chain_length:.1f}")
        print(f"  ‚úÖ Constraint: {'SATISFIED' if best_chain_length >= MIN_CHAIN_LENGTH else 'VIOLATED'}")
    print(f"  üéØ Best Objective: {best_objective:.2f}")
    print("-" * 60)

    # ÂàÜÊûêÁ∫¶ÊùüÊª°Ë∂≥ÊÉÖÂÜµ
    history_df = pd.DataFrame(optimization_history)
    satisfied_count = sum(1 for cl in history_df['chain_lengths'] if cl >= MIN_CHAIN_LENGTH)
    print(f"\nüìä CONSTRAINT SATISFACTION ANALYSIS:")
    print(f"  ‚úÖ Satisfied evaluations: {satisfied_count}/{len(history_df)} ({satisfied_count/len(history_df)*100:.1f}%)")
    print(f"  üìà Average chain length: {history_df['chain_lengths'].mean():.1f}")
    print(f"  üìä Chain length range: {history_df['chain_lengths'].min():.1f} - {history_df['chain_lengths'].max():.1f}")

    # ÂàõÂª∫‰ºòÂåñÂõæË°®
    create_constrained_optimization_plots(result_gp, best_temp, best_ratio, best_objective, history_df)

    return result_gp

def create_constrained_optimization_plots(result_gp, best_temp, best_ratio, best_objective, history_df):
    """
    Create a single, publication-quality dashboard visualizing the constrained optimization process.
    Titles on subplots are removed.
    """
    print("\nüìä Generating Enhanced Optimization Dashboard...")

    # --- 1. ËÆæÁΩÆÈ´òÁ∫ßÁªòÂõæÈ£éÊ†º ---
    plt.style.use('seaborn-v0_8-ticks')
    plt.rcParams.update({
        'font.family': 'serif',
        'font.size': 14,
        'axes.labelsize': 16,
        'axes.titlesize': 18,
        'axes.labelweight': 'bold',
        'axes.titleweight': 'bold',
        'legend.fontsize': 12,
        'xtick.major.size': 7,
        'ytick.major.size': 7,
        'xtick.minor.size': 4,
        'ytick.minor.size': 4,
        'xtick.direction': 'in',
        'ytick.direction': 'in',
        'axes.linewidth': 1.5,
    })

    # --- 2. ÂàõÂª∫ÂõæÂΩ¢ÂíåÂ∏ÉÂ±Ä ---
    fig = plt.figure(figsize=(20, 10))
    gs = fig.add_gridspec(2, 2, width_ratios=(1.8, 1), height_ratios=(1, 1), hspace=0.35, wspace=0.25)

    ax_main = fig.add_subplot(gs[:, 0])
    ax_conv = fig.add_subplot(gs[0, 1])
    ax_constraint = fig.add_subplot(gs[1, 1])

    # --- 3. ‰∏ªÂõæÔºöÂèÇÊï∞Á©∫Èó¥Êé¢Á¥¢ ---
    satisfied_mask = history_df['chain_lengths'] >= MIN_CHAIN_LENGTH

    temp_grid, ratio_grid = np.meshgrid(
        np.linspace(min(temp_values), max(temp_values), 100),
        np.linspace(min(ratio_values), max(ratio_values), 100)
    )
    time_grid = griddata((history_df['temperatures'], history_df['ratios']),
                         history_df['total_times'],
                         (temp_grid, ratio_grid), method='cubic')

    contour = ax_main.contourf(temp_grid, ratio_grid, time_grid, levels=20, cmap='viridis_r', alpha=0.7)
    cbar = fig.colorbar(contour, ax=ax_main, orientation='vertical', pad=0.02)
    cbar.set_label('Interpolated Total Cycle Time (s)', rotation=270, labelpad=20)

    ax_main.scatter(
        history_df.loc[satisfied_mask, 'temperatures'],
        history_df.loc[satisfied_mask, 'ratios'],
        c='lime', s=100,
        marker='o', edgecolors='k', linewidth=1.5,
        alpha=1.0, label='Constraint Satisfied'
    )

    ax_main.scatter(
        history_df.loc[~satisfied_mask, 'temperatures'],
        history_df.loc[~satisfied_mask, 'ratios'],
        c='red', s=120,
        marker='x', linewidth=3,
        alpha=1.0, label='Constraint Violated'
    )

    ax_main.plot(best_temp, best_ratio, marker='*', color='gold', markersize=25,
                 markeredgecolor='black', markeredgewidth=1.5,
                 label=f'Optimum ({best_temp:.1f}K, {best_ratio:.4f})')

    ax_main.set_xlabel("Temperature (K)")
    ax_main.set_ylabel("Initiator Ratio")
    # ax_main.set_title("Parameter Space Exploration") # <-- Â∑≤ÁßªÈô§
    ax_main.legend(loc='best')
    ax_main.minorticks_on()

    # --- 4. Âè≥‰∏äÔºöÊî∂ÊïõÂõæ ---
    from skopt.plots import plot_convergence
    plot_convergence(result_gp, ax=ax_conv)
    # ax_conv.set_title("Convergence of Objective Function") # <-- Ê†áÈ¢òÂ∑≤Ë¢´ÁßªÈô§
    ax_conv.set_xlabel("Number of Calls")
    ax_conv.set_ylabel("Best Objective Value Found")
    ax_conv.grid(True, which='major', linestyle='--', alpha=0.6)
    ax_conv.minorticks_on()

    # --- 5. Âè≥‰∏ãÔºöÁ∫¶ÊùüÊª°Ë∂≥ÊÉÖÂÜµ ---
    iterations = np.arange(1, len(history_df) + 1)
    chain_lengths = history_df['chain_lengths'].values

    ax_constraint.plot(iterations, chain_lengths, marker='', ls='-', color='lightgray', lw=2)

    ax_constraint.scatter(iterations[satisfied_mask], chain_lengths[satisfied_mask],
                          color='green', s=80, zorder=5, label='Satisfied', edgecolors='k', linewidth=1)
    ax_constraint.scatter(iterations[~satisfied_mask], chain_lengths[~satisfied_mask],
                          color='red', s=80, zorder=5, label='Violated', edgecolors='k', linewidth=1)

    ax_constraint.axhline(y=MIN_CHAIN_LENGTH, color='blue', linestyle='--', linewidth=2.5,
                          label=f'Constraint (‚â• {MIN_CHAIN_LENGTH:.0f})')

    ax_constraint.set_xlabel("Number of Calls")
    ax_constraint.set_ylabel("Average Chain Length")
    # ax_constraint.set_title("Chain Length Constraint Fulfillment") # <-- Â∑≤ÁßªÈô§
    ax_constraint.legend()
    ax_constraint.set_ylim(bottom=0)
    ax_constraint.set_xlim(0, len(iterations) + 1)
    ax_constraint.minorticks_on()

    # --- 6. Ê∑ªÂä†ÊÄªÊ†áÈ¢òÂπ∂‰øùÂ≠ò ---
    fig.suptitle(f"Bayesian Optimization Dashboard (Target: Minimize Time, Constraint: Chain Length ‚â• {MIN_CHAIN_LENGTH:.0f})",
                 fontsize=24, y=0.98)

    output_filename = 'new_1000__bayesian_optimization_dashboard_notitle.png'
    plt.savefig(output_filename, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print(f"‚úÖ Optimization dashboard (no subtitles) saved: '{output_filename}'")

# =================================================================
# 5. MAIN EXECUTION
# =================================================================

if __name__ == "__main__":
    print("üöÄ PMMA LIFECYCLE SIMULATION FRAMEWORK WITH CHAIN LENGTH CONSTRAINTS")
    print("Investigating polymerization conditions ‚Üí structural defects ‚Üí recyclability")
    print(f"üîó Chain Length Constraint: Average length ‚â• {MIN_CHAIN_LENGTH}")
    print("="*80)

    # Step 1: Single detailed analysis
    if DO_SINGLE_ANALYSIS:
        run_single_analysis(ANALYSIS_TEMP, ANALYSIS_RATIO, ANALYSIS_OUTPUT_DIR)

    # Step 2: Parameter sweep for defect investigation
    sweep_df = None
    if DO_PARAMETER_SWEEP:
        sweep_df = run_parameter_sweep()

        if sweep_df is not None:
            # Analyze correlations
            analyze_defect_correlations(sweep_df)

            # Create comprehensive plots
            create_comprehensive_defect_analysis_plots(sweep_df)

    # Step 3: Constrained Bayesian optimization
    if DO_OPTIMIZATION:
        optimization_result = run_bayesian_optimization()

    # Final summary
    print("\n" + "="*80)
    print("üéâ CONSTRAINED PMMA LIFECYCLE INVESTIGATION COMPLETE!")
    print("="*80)

    summary_parts = []
    if DO_SINGLE_ANALYSIS:
        summary_parts.append(f"‚úÖ Single analysis completed (T={ANALYSIS_TEMP}K, R={ANALYSIS_RATIO})")
    if DO_PARAMETER_SWEEP and sweep_df is not None:
        summary_parts.append(f"‚úÖ Parameter sweep completed ({len(sweep_df)} simulations)")
    if DO_OPTIMIZATION:
        summary_parts.append(f"‚úÖ Constrained Bayesian optimization completed (Chain Length ‚â• {MIN_CHAIN_LENGTH})")

    for part in summary_parts:
        print(part)

    print("\nüìä Generated Analysis Files:")
    if DO_SINGLE_ANALYSIS:
        print(f"  üìÅ Single analysis: {ANALYSIS_OUTPUT_DIR}/")
    if DO_PARAMETER_SWEEP:
        print(f"  üìÅ Parameter sweep: {SWEEP_OUTPUT_DIR}/")
        print(f"  üìä Comprehensive plot: comprehensive_defect_analysis.png")
    if DO_OPTIMIZATION:
        print(f"  üìä Constrained optimization plots: constrained_optimization_*.png")

    print("\nüî¨ This enhanced framework provides comprehensive insights into:")
    print("  1Ô∏è‚É£  How temperature and initiator ratio affect defect formation")
    print("  2Ô∏è‚É£  Correlations between structural defects and recyclability")
    print("  3Ô∏è‚É£  Optimal synthesis conditions with chain length constraints")
    print("  4Ô∏è‚É£  Complete PMMA lifecycle modeling from synthesis to recycling")
    print("  5Ô∏è‚É£  Trade-offs between process efficiency, product quality, and chain length")
    print("  6Ô∏è‚É£  Constraint satisfaction analysis in optimization")

    if not any([DO_SINGLE_ANALYSIS, DO_PARAMETER_SWEEP, DO_OPTIMIZATION]):
        print("‚ö†Ô∏è  All analysis modes are disabled. Enable at least one mode in the configuration section.")